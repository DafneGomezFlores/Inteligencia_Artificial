{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NOMBRE: GOMEZ GARCIA FLORES DAFNE JULY\n",
        "CI: 13119227\n",
        "CU: 35-3800\n",
        "\n",
        "\n",
        "\n",
        "Predicción de la calidad del agua      \n",
        "Número de instancias (ejemplos): 705\n",
        "\n",
        "Número de características (atributos): 11\n",
        "\n",
        "Prediccion de la calidad de agua\n",
        "contiene mediciones de calidad tomadas en 36 sitios de monitoreo en EE.UU\n",
        "cada registro representa nuestra diaria del agua en un sitio especifico.\n",
        "incluye 11 caracteristicas que representan diferentes aspectos de agua,como:\n",
        "oxigeno disuelto, temperatura, conductividad y otros indicadores quimicos y fisicos.\n",
        "este dataset cumple el predecir el valor de pH del agua para el dia siguiente, usando los calores actuales y pasados de las caracteristicas.\n",
        "es un problema de regresion ya que el pH es un valor continuo.\n",
        "este dataset se utiliza para modelos de prediccion de series de tiempo y aprendizaje automatico y regresion.\n",
        "permite entrenar modelos para anticipar la calidad de agua y ayudar en gestion ambiental y decisiones de tratamiento de agua.\n"
      ],
      "metadata": {
        "id": "slKnE0ykQUMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lo primero que hacemos es importas librerías: pandas, numpy y PyTorch para manejar datos, crear la red y entrenarla. También matplotlib para ver los resultados."
      ],
      "metadata": {
        "id": "zqg9tRG4RVYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3IpOgt9PTcU"
      },
      "outputs": [],
      "source": [
        "# 1. Importar librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asi tambien empezamos a cargas el dataset water_quality.csv y revisas las primeras filas para familiarizarte con los datos."
      ],
      "metadata": {
        "id": "iuA_-nSTRZ9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Cargar dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/PrediccionAgua.mat.csv')  # reemplaza con tu archivo\n",
        "print(\"Primeras filas del dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "jMB4EGCCPcnn",
        "outputId": "51a5e86a-249b-4d94-add0-e25a03c889fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/PrediccionAgua.mat.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1452348144.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2. Cargar dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/PrediccionAgua.mat.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reemplaza con tu archivo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Primeras filas del dataset:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/PrediccionAgua.mat.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "separamos las variables.\n",
        "\n",
        "X: todas las características que describen la calidad del agua (excepto pH).\n",
        "\n",
        "y: el valor de pH que queremos predecir."
      ],
      "metadata": {
        "id": "aWwIawRGRk_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Separar características y variable objetivo\n",
        "X = df.drop(columns=['pH']).values  # todas las columnas menos 'pH'\n",
        "y = df['pH'].values.reshape(-1,1)   # variable a predecir"
      ],
      "metadata": {
        "id": "4OTKC6XNPfxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se normaliza los datos entre 0 y 1 con MinMaxScaler, porque las redes aprenden mejor con valores pequeños y consistentes."
      ],
      "metadata": {
        "id": "-6pm6443RqeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Normalizar los datos\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n"
      ],
      "metadata": {
        "id": "QO9BsOROPnKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creas secuencias de 7 días, usando los valores de los últimos 7 días para predecir el pH del día siguiente. Esto convierte tus datos en un problema de serie de tiempo."
      ],
      "metadata": {
        "id": "hZgO8ttqR2EX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Crear secuencias de series de tiempo (7 días anteriores para predecir el siguiente)\n",
        "def create_sequences(X, y, seq_length=7):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - seq_length):\n",
        "        X_seq.append(X[i:i+seq_length].flatten())  # aplanar características\n",
        "        y_seq.append(y[i+seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "seq_length = 7\n",
        "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)"
      ],
      "metadata": {
        "id": "ODDRKJLrPqV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conviertes los datos a tensores de PyTorch, que es el formato que necesita la red para entrenar."
      ],
      "metadata": {
        "id": "VfBiCm21R75U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Convertir a tensores de PyTorch\n",
        "X_tensor = torch.from_numpy(X_seq).float()\n",
        "y_tensor = torch.from_numpy(y_seq).float()"
      ],
      "metadata": {
        "id": "uuRZPCyAPvW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divides en entrenamiento y prueba, usando 80% para entrenar y 20% para evaluar, sin mezclar el orden porque es una serie temporal."
      ],
      "metadata": {
        "id": "Q0W2QliPR_VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Dividir en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, shuffle=False)\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "BLWs8ek7PzUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines la red neuronal:\n",
        "\n",
        "Capa de entrada (fc1) → 64 neuronas\n",
        "\n",
        "Capa oculta (fc2) → 32 neuronas\n",
        "\n",
        "Capa de salida → 1 neurona (predicción del pH)\n",
        "\n",
        "Función ReLU para introducir no linealidad."
      ],
      "metadata": {
        "id": "j1Hlus7aSEP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Definir la red neuronal\n",
        "class WaterQualityNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(WaterQualityNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "input_size = X_seq.shape[1]  # número de características * sec_length\n",
        "model = WaterQualityNN(input_size)"
      ],
      "metadata": {
        "id": "RiF8zI8iP36n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuras el entrenamiento:\n",
        "\n",
        "MSELoss para medir error cuadrático medio.\n",
        "\n",
        "Adam como optimizador para ajustar los pesos de la red."
      ],
      "metadata": {
        "id": "BNt7dU-nSLx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Configurar pérdida y optimizador\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "GkygvkdXP8px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenas la red durante 150 épocas. Para cada batch de datos, calculas predicción, pérdida, y ajustas los pesos."
      ],
      "metadata": {
        "id": "OecbfvnVSSVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Entrenamiento de la red\n",
        "epochs = 150\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch+1) % 30 == 0:\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}')"
      ],
      "metadata": {
        "id": "dPKFP6cLQAvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evalúas la red en los datos de prueba y transformas los valores a la escala original de pH."
      ],
      "metadata": {
        "id": "YTfd3wy-SYuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Evaluación y predicción\n",
        "model.eval()\n",
        "predictions = model(X_test).detach().numpy()\n",
        "predictions_rescaled = scaler_y.inverse_transform(predictions)\n",
        "y_test_rescaled = scaler_y.inverse_transform(y_test.numpy())"
      ],
      "metadata": {
        "id": "QH-m5LeFQGvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizas los resultados en un gráfico comparando pH real y pH predicho, para ver qué tan bien aprendió la red."
      ],
      "metadata": {
        "id": "xLmg_n8RScez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Visualizar resultados\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_test_rescaled, label='pH real')\n",
        "plt.plot(predictions_rescaled, label='pH predicho')\n",
        "plt.xlabel('Día')\n",
        "plt.ylabel('pH')\n",
        "plt.title('Predicción de pH del agua')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0RVV1IHjQKOk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}